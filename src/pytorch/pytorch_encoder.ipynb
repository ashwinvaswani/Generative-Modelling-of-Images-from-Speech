{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_encoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinvaswani/Generative-Modelling-of-Images-from-Speech/blob/master/src/pytorch/pytorch_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqIfeo5u_Rih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SOetddtDi83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqJcoA6xDlPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,sampler,Dataset\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import timeit\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import torchvision.models.inception as inception\n",
        "import cv2\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtAIqDkDlRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './drive/My Drive/TIP/Dataset/'\n",
        "PATH_TO_MAIN = './drive/My Drive/TIP/'\n",
        "YT_LINK = 'www.youtube.com/watch?v='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0gRZQCdDnhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(PATH_TO_MAIN + 'Pickles/encoder_trainX.pkl','rb') as f:\n",
        "    x_enc_train = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-AOtHVQDoIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(PATH_TO_MAIN + 'Pickles/encoder_trainY.pkl','rb') as f:\n",
        "    y_train_encoder= pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfBOP1NSDp3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_enc_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HEbpFbYDsbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(x_enc_train,y_train_encoder,test_size = 0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDpoFgN5Ds-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR09Xb96DtAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.cuda.FloatTensor # the CPU datatype\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 10\n",
        "# This is a little utility that we'll use to reset the model\n",
        "# if we want to re-initialize all our parameters\n",
        "def reset(m):\n",
        "    if hasattr(m, 'reset_parameters'):\n",
        "        m.reset_parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5vRB3yiD1U8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-y2Ig9AD3Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Conv2d(2, 64, kernel_size=(4,4), stride=(1,1)),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.Conv2d(64, 64, kernel_size=4, stride=1),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.Conv2d(64, 128, kernel_size=4, stride=1),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.MaxPool2d(kernel_size = (2,1),stride = (2,1)),\n",
        "                nn.Conv2d(128, 128, kernel_size=4, stride=1),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.MaxPool2d(kernel_size = (2,1),stride = (2,1)),\n",
        "                nn.Conv2d(128, 256, kernel_size=4, stride=1),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.MaxPool2d(kernel_size = (2,1),stride = (2,1)),\n",
        "                nn.Conv2d(256, 512, kernel_size=4, stride=1),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(512),\n",
        "                nn.Conv2d(512, 512, kernel_size=4, stride=2),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(512),\n",
        "                nn.Conv2d(512, 512, kernel_size=4, stride=2),\n",
        "                nn.AvgPool2d(kernel_size = (15,1),stride = (1,1)),\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.BatchNorm2d(512),\n",
        "                Flatten(),\n",
        "                nn.Linear(29696, 4096),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(4096,2048)\n",
        "            )\n",
        "\n",
        "\n",
        "fixed_model = fixed_model_base.type(dtype)\n",
        "\n",
        "fixed_model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lqaPTNVD341",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(fixed_model,(2,598,257))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPdWcxzkD7eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(16, 2, 598, 257).type(dtype)\n",
        "x_var = Variable(x.type(dtype)) # Construct a PyTorch Variable out of your input data\n",
        "ans = fixed_model(x_var)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "print(np.array(ans.size()))\n",
        "np.array_equal(np.array(ans.size()), np.array([16,2048]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhwyTV1XD9Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer, x_train,y_train,x_val,y_val, num_epochs = 1):\n",
        "    # Early stopping details\n",
        "    n_epochs_stop = 15\n",
        "    min_val_loss = np.Inf\n",
        "    epochs_no_improve = 0\n",
        "    max_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        val_loss = 0\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        print(type(x_val),type(y_val))\n",
        "        val_loss,val_acc = check_accuracy(fixed_model,x_val,y_val ,loss_fn,val_loss)# check accuracy on the training set\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        model.train()\n",
        "        for t in range(len(x_train)):\n",
        "            x_var = Variable(torch.from_numpy(x_train[t]).type(dtype))\n",
        "            y_var = Variable(torch.from_numpy(y_train[t])).type(dtype)\n",
        "\n",
        "            scores = model(x_var)\n",
        "            \n",
        "            loss = loss_fn(scores, y_var)\n",
        "            if (t + 1) % print_every == 0:\n",
        "                #print('t = %d, loss = %.4f' % (t + 1, loss.data))\n",
        "                print(\"training loss : \" + str(loss.item()))\n",
        "                print(scores)\n",
        "                print(y_var)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        val_loss = val_loss / len(x_val)\n",
        "        print(\"valid loss : \" + str(val_loss))\n",
        "        if val_acc > max_acc:\n",
        "            torch.save({'state_dict': fixed_model.state_dict()}, 'tmp_new_best.pt')\n",
        "            print(\"Best Model Saved\")\n",
        "            max_acc = val_acc\n",
        "        \n",
        "        if val_loss < min_val_loss:\n",
        "            torch.save({'state_dict': fixed_model.state_dict()}, 'tmp_new.pt')\n",
        "            torch.save(fixed_model.state_dict(), 'tmp_new_model.pt')\n",
        "            print(\"Model saved\")\n",
        "            current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "            epochs_no_improve = 0\n",
        "            min_val_loss = val_loss\n",
        "  \n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            # Check early stopping condition\n",
        "            if epochs_no_improve == n_epochs_stop:\n",
        "                print('Early stopping!')\n",
        "                epochs_no_improve = 0\n",
        "                #break\n",
        "                # Load in the best model\n",
        "                model = fixed_model_base.type(dtype)\n",
        "                model.load_state_dict(torch.load('tmp_new_model.pt'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydu1g4hrD-7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy(model,x_val,y_val,loss_fn,val_loss):\n",
        "    '''\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')  \n",
        "    '''\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    #print(type(x_val),x_val)\n",
        "\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    x = 0\n",
        "    for t  in range(len(x_val)):\n",
        "        x_var = torch.from_numpy(x_val[t]).type(dtype)\n",
        "        y_var = torch.from_numpy(y_val[t]).type(dtype)\n",
        "        scores = model(x_var)\n",
        "        loss = loss_fn(scores,y_var)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "        \n",
        "        _, preds = scores.data.max(1) #scores.data.cpu().max(1)\n",
        "\n",
        "        num_correct += (preds.cpu().numpy() == y_var.cpu().numpy()).sum()\n",
        "\n",
        "        \n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    \n",
        "    return val_loss,acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftWVmmlcD_t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(fixed_model_base.parameters(), lr = 0.001)\n",
        "#optimizer = torch.optim.Adadelta(fixed_model_base.parameters(), lr = 0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=15,verbose = True)\n",
        "#loss_fn = nn.MultiMarginLoss()\n",
        "loss_fn = nn.MSELoss()\n",
        "X_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAmQTtxxEII-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.reshape(X_train,(39,1,2,598,257))\n",
        "X_val = np.reshape(X_val,(3,1,2,598,257))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAqJRedVEJ3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt5zHCc4ELjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.reshape(y_train,(39,1,2048))\n",
        "y_val = np.reshape(y_val,(3,1,2048))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Zj5FcTEMJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4g2TKXvEQwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.random.manual_seed(54321)\n",
        "fixed_model.apply(reset) \n",
        "fixed_model.train() \n",
        "train(fixed_model, loss_fn, optimizer,X_train,y_train,X_val,y_val, num_epochs=10) \n",
        "# check_accuracy(fixed_model,zip(X_train,y_train), ,loss_fn,0) #heck accuracy on the training set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjM_tOtkE9KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({'state_dict': fixed_model.state_dict()}, PATH_TO_MAIN + 'Models/pytorch_encoders.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}