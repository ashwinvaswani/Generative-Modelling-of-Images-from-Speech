{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_decoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinvaswani/Generative-Modelling-of-Images-from-Speech/blob/master/src/pytorch/pytorch_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEJ9ObMK_Wnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCb8GbahEluY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQoUlKkEmOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,sampler,Dataset\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import timeit\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import torchvision.models.inception as inception\n",
        "import cv2\n",
        "from torchsummary import summary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2_bhLyUEphJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './drive/My Drive/TIP/Dataset/'\n",
        "PATH_TO_MAIN = './drive/My Drive/TIP/'\n",
        "YT_LINK = 'www.youtube.com/watch?v='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0ljzNDAEs1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(PATH_TO_MAIN + 'Pickles/y_pred_encoder.pkl','rb') as f:\n",
        "    x_train_decoder= pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImE8cq8qEuK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = []\n",
        "for elem in os.listdir('./Images'):\n",
        "  filenames.append(elem)\n",
        "\n",
        "decoder_train_df = pd.DataFrame(filenames,columns = ['filename'])\n",
        "decoder_train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2HgqohiEu84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Np9nxSfEvUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load y_train_decoder from images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox30Hm49Evar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test train split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGe828C4FScs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.cuda.FloatTensor # the CPU datatype\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 10\n",
        "# This is a little utility that we'll use to reset the model\n",
        "# if we want to re-initialize all our parameters\n",
        "def reset(m):\n",
        "    if hasattr(m, 'reset_parameters'):\n",
        "        m.reset_parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1DqqI6yFUER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vedUjhDcE0NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6P61bFPFV8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
        "x = torch.randn(16, 2, 598, 257).type(dtype)\n",
        "x_var = Variable(x.type(dtype)) # Construct a PyTorch Variable out of your input data\n",
        "ans = fixed_model(x_var)        # Feed it through the model! \n",
        "\n",
        "# Check to make sure what comes out of your model\n",
        "# is the right dimensionality... this should be True\n",
        "# if you've done everything correctly\n",
        "print(np.array(ans.size()))\n",
        "np.array_equal(np.array(ans.size()), np.array([16,2048]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuwApae3FZAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer, x_train,y_train,x_val,y_val, num_epochs = 1):\n",
        "    # Early stopping details\n",
        "    n_epochs_stop = 15\n",
        "    min_val_loss = np.Inf\n",
        "    epochs_no_improve = 0\n",
        "    max_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        val_loss = 0\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        print(type(x_val),type(y_val))\n",
        "        val_loss,val_acc = check_accuracy(fixed_model,x_val,y_val ,loss_fn,val_loss)# check accuracy on the training set\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        model.train()\n",
        "        for t in range(len(x_train)):\n",
        "            x_var = Variable(torch.from_numpy(x_train[t]).type(dtype))\n",
        "            y_var = Variable(torch.from_numpy(y_train[t])).type(dtype)\n",
        "\n",
        "            scores = model(x_var)\n",
        "            \n",
        "            loss = loss_fn(scores, y_var)\n",
        "            if (t + 1) % print_every == 0:\n",
        "                #print('t = %d, loss = %.4f' % (t + 1, loss.data))\n",
        "                print(\"training loss : \" + str(loss.item()))\n",
        "                print(scores)\n",
        "                print(y_var)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        val_loss = val_loss / len(x_val)\n",
        "        print(\"valid loss : \" + str(val_loss))\n",
        "        if val_acc > max_acc:\n",
        "            torch.save({'state_dict': fixed_model.state_dict()}, 'tmp_new_best.pt')\n",
        "            print(\"Best Model Saved\")\n",
        "            max_acc = val_acc\n",
        "        \n",
        "        if val_loss < min_val_loss:\n",
        "            torch.save({'state_dict': fixed_model.state_dict()}, 'tmp_new.pt')\n",
        "            torch.save(fixed_model.state_dict(), 'tmp_new_model.pt')\n",
        "            print(\"Model saved\")\n",
        "            current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "            epochs_no_improve = 0\n",
        "            min_val_loss = val_loss\n",
        "  \n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            # Check early stopping condition\n",
        "            if epochs_no_improve == n_epochs_stop:\n",
        "                print('Early stopping!')\n",
        "                epochs_no_improve = 0\n",
        "                #break\n",
        "                # Load in the best model\n",
        "                model = fixed_model_base.type(dtype)\n",
        "                model.load_state_dict(torch.load('tmp_new_model.pt'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGZ6nkpsFaf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy(model,x_val,y_val,loss_fn,val_loss):\n",
        "    '''\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')  \n",
        "    '''\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    #print(type(x_val),x_val)\n",
        "\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    x = 0\n",
        "    for t  in range(len(x_val)):\n",
        "        x_var = torch.from_numpy(x_val[t]).type(dtype)\n",
        "        y_var = torch.from_numpy(y_val[t]).type(dtype)\n",
        "        scores = model(x_var)\n",
        "        loss = loss_fn(scores,y_var)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "        \n",
        "        _, preds = scores.data.max(1) #scores.data.cpu().max(1)\n",
        "\n",
        "        num_correct += (preds.cpu().numpy() == y_var.cpu().numpy()).sum()\n",
        "\n",
        "        \n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    \n",
        "    return val_loss,acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dfUjFzOFhxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Is9dB40Fhzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mca0qhNgFcB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(fixed_model_base.parameters(), lr = 0.001)\n",
        "#optimizer = torch.optim.Adadelta(fixed_model_base.parameters(), lr = 0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=15,verbose = True)\n",
        "#loss_fn = nn.MultiMarginLoss()\n",
        "loss_fn = nn.MSELoss()\n",
        "X_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLzEUeTVFdg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6yZFeaQFil4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTtifIROFinx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJsHROjwFip_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({'state_dict': fixed_model.state_dict()}, PATH_TO_MAIN + 'Models/pytorch_decoders.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}