{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinvaswani/Generative-Modelling-of-Images-from-Speech/blob/master/src/TIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nalKfifObQ",
        "colab_type": "code",
        "outputId": "b7356899-7ab8-440b-8403-54b8ec026918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install pydub\n",
        "!pip install pytube\n",
        "!pip install mtcnn\n",
        "!pip install keras-vggface"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n",
            "Collecting pytube\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/00/62118c1e9e597aed08ddf7d9a6ca45ec95147367280aba73e8b82816fec1/pytube-9.5.3-py3-none-any.whl\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-9.5.3\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/c7/8546b18fbd367b156c5bbbbaa8912ab31c8129171523ff8b47b546d70b09/mtcnn-0.0.9.tar.gz (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mtcnn\n",
            "  Building wheel for mtcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtcnn: filename=mtcnn-0.0.9-cp36-none-any.whl size=2257690 sha256=ed6d4dec8a725160e1b162e65cd19fa866816a49847c95be177d0129e8a0bdad\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/81/65/6363fa5aafd7a155c896591e0c7c6e27b69642aa82b9cbf076\n",
            "Successfully built mtcnn\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.0.9\n",
            "Collecting keras-vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.2.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (4.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.0.8)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface) (0.46)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag9GmoUm-5Q3",
        "colab_type": "code",
        "outputId": "b00a7cb9-0613-4b5e-bb9e-2ad73efe2d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2 \n",
        "import os\n",
        "import sys\n",
        "import moviepy.editor as mp\n",
        "import pickle\n",
        "\n",
        "import math\n",
        "from math import ceil\n",
        "from math import floor\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pytube import YouTube\n",
        "\n",
        "import shutil\n",
        "\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import dlib\n",
        "\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3334144/45929032 bytes (7.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7323648/45929032 bytes (15.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11329536/45929032 bytes (24.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15237120/45929032 bytes (33.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19111936/45929032 bytes (41.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23076864/45929032 bytes (50.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27033600/45929032 bytes (58.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30965760/45929032 bytes (67.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34889728/45929032 bytes (76.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38821888/45929032 bytes (84.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42754048/45929032 bytes (93.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbnCURGp_E8W",
        "colab_type": "code",
        "outputId": "67b8e691-7fd7-4af8-981b-abb5d37a6845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZAtSuy6_I3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './drive/My Drive/TIP/Dataset/'\n",
        "PATH_TO_MAIN = './drive/My Drive/TIP/'\n",
        "YT_LINK = 'www.youtube.com/watch?v='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gql85lJ_UX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['YouTube_ID', 'start_segment', 'end_segment', 'X_coordinate', 'Y_coordinate']\n",
        "train_df = pd.read_csv(PATH + 'avspeech_train.csv',names = column_names)\n",
        "test_df = pd.read_csv(PATH + 'avspeech_test.csv',names = column_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNkryG8n_u4g",
        "colab_type": "code",
        "outputId": "e4be2e16-1dea-40fd-d399-98f7c92e9c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YouTube_ID</th>\n",
              "      <th>start_segment</th>\n",
              "      <th>end_segment</th>\n",
              "      <th>X_coordinate</th>\n",
              "      <th>Y_coordinate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CJoOwXcjhds</td>\n",
              "      <td>233.266000</td>\n",
              "      <td>239.367000</td>\n",
              "      <td>0.780469</td>\n",
              "      <td>0.670833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AvWWVOgaMlk</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>93.566667</td>\n",
              "      <td>0.586719</td>\n",
              "      <td>0.311111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Y8HMIm8mdns</td>\n",
              "      <td>171.607767</td>\n",
              "      <td>174.607767</td>\n",
              "      <td>0.505729</td>\n",
              "      <td>0.240741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>akwvpAiLFk0</td>\n",
              "      <td>144.680000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>0.698438</td>\n",
              "      <td>0.288889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Swss72CHSWg</td>\n",
              "      <td>90.023267</td>\n",
              "      <td>97.297200</td>\n",
              "      <td>0.230729</td>\n",
              "      <td>0.204630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YouTube_ID  start_segment  end_segment  X_coordinate  Y_coordinate\n",
              "0  CJoOwXcjhds     233.266000   239.367000      0.780469      0.670833\n",
              "1  AvWWVOgaMlk      90.000000    93.566667      0.586719      0.311111\n",
              "2  Y8HMIm8mdns     171.607767   174.607767      0.505729      0.240741\n",
              "3  akwvpAiLFk0     144.680000   150.000000      0.698438      0.288889\n",
              "4  Swss72CHSWg      90.023267    97.297200      0.230729      0.204630"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwN707L_x-H",
        "colab_type": "code",
        "outputId": "a3219013-61d0-40a9-ac07-f264915b4175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YouTube_ID</th>\n",
              "      <th>start_segment</th>\n",
              "      <th>end_segment</th>\n",
              "      <th>X_coordinate</th>\n",
              "      <th>Y_coordinate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u5MPyrRJPmc</td>\n",
              "      <td>108.2400</td>\n",
              "      <td>111.240000</td>\n",
              "      <td>0.849219</td>\n",
              "      <td>0.305556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H1ulMfj5wRY</td>\n",
              "      <td>112.3200</td>\n",
              "      <td>116.940000</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.345833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-wuxbgMRIWs</td>\n",
              "      <td>30.0300</td>\n",
              "      <td>36.745044</td>\n",
              "      <td>0.744531</td>\n",
              "      <td>0.211111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GNRPRH-E-sI</td>\n",
              "      <td>30.2302</td>\n",
              "      <td>38.171467</td>\n",
              "      <td>0.333594</td>\n",
              "      <td>0.494444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VvcwAGkSy2o</td>\n",
              "      <td>240.2000</td>\n",
              "      <td>253.366667</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>0.372222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YouTube_ID  start_segment  end_segment  X_coordinate  Y_coordinate\n",
              "0  u5MPyrRJPmc       108.2400   111.240000      0.849219      0.305556\n",
              "1  H1ulMfj5wRY       112.3200   116.940000      0.112500      0.345833\n",
              "2  -wuxbgMRIWs        30.0300    36.745044      0.744531      0.211111\n",
              "3  GNRPRH-E-sI        30.2302    38.171467      0.333594      0.494444\n",
              "4  VvcwAGkSy2o       240.2000   253.366667      0.491667      0.372222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPS_NJEsVX2v",
        "colab_type": "code",
        "outputId": "59391b6c-12f5-4139-c639-d55e8f72fb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "YT_LINK + train_df.iloc[2][\"YouTube_ID\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'www.youtube.com/watch?v=Y8HMIm8mdns'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOenYxt1VJQM",
        "colab_type": "code",
        "outputId": "f3cf21f1-4e15-4f51-fca2-e0a24598903a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "\n",
        "# shutil.rmtree('Images')\n",
        "# shutil.rmtree('Audio')\n",
        "# shutil.rmtree('Videos')\n",
        "os.mkdir(\"Images\")\n",
        "os.mkdir(\"Audio\")\n",
        "os.mkdir(\"Videos\")\n",
        "\n",
        "len_train = train_df.shape[0]\n",
        "count_unsuccessful = 0\n",
        "dict_audio = {}\n",
        "\n",
        "for i in range(1,4):\n",
        "\n",
        "  print(YT_LINK + train_df.iloc[i][\"YouTube_ID\"])\n",
        "  try:\n",
        "    yt = YouTube(YT_LINK + train_df.iloc[i][\"YouTube_ID\"])\n",
        "    stream = yt.streams.first()\n",
        "    stream.download(output_path = 'Videos/',filename = train_df.iloc[i][\"YouTube_ID\"])\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(\"Videos/\" + train_df.iloc[i][\"YouTube_ID\"] + '.mp4') \n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    \n",
        "    count = 0\n",
        "\n",
        "    dir_name = train_df.iloc[i][\"YouTube_ID\"]\n",
        "    \n",
        "    print(\"FPS is : \"  + str(fps))\n",
        "    start_cnt = train_df.iloc[i][\"start_segment\"]\n",
        "    end_cnt = train_df.iloc[i][\"end_segment\"]\n",
        "    \n",
        "    while(1):\n",
        "\n",
        "        ret,frame = cap.read()\n",
        "\n",
        "        if ret == 1:\n",
        "\n",
        "          count += 1\n",
        "\n",
        "          (h, w) = frame.shape[:2]\n",
        "\n",
        "          if (((start_cnt + end_cnt)*fps)/2) - 16 < count < (((start_cnt + end_cnt)*fps)/2) + 16:\n",
        "            dnnFaceDetector = dlib.cnn_face_detection_model_v1( PATH_TO_MAIN + \"Face_detection/mmod_human_face_detector.dat\")\n",
        "            faceRects = dnnFaceDetector(frame, 0)\n",
        "            print(faceRects)\n",
        "            for faceRect in faceRects:\n",
        "                x1 = faceRect.rect.left()\n",
        "                y1 = faceRect.rect.top()\n",
        "                x2 = faceRect.rect.right()\n",
        "                y2 = faceRect.rect.bottom()\n",
        "                img = frame[y1:y2, x1:x2]\n",
        "                print(\"About to crop\")\n",
        "                print(count)\n",
        "                img = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                cv2.imwrite('Images/' +dir_name + '.png', img)\n",
        "            break\n",
        "\n",
        "\n",
        "          if count > int(end_cnt*fps):\n",
        "            break\n",
        "          k = cv2.waitKey(1)\n",
        "          if k == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "  except:\n",
        "    print(\"SORRY!!! The video is unavailable\")\n",
        "    count_unsuccessful += 1\n",
        "    \n",
        "  try:\n",
        "    clip = mp.VideoFileClip(\"Videos/\" + train_df.iloc[i][\"YouTube_ID\"] + '.mp4').subclip(start_cnt,end_cnt)\n",
        "    clip.audio.write_audiofile(\"Audio/\" + train_df.iloc[i][\"YouTube_ID\"] +'.mp3') \n",
        "    print(\"before dict\")\n",
        "    dict_audio[train_df.iloc[i][\"YouTube_ID\"]] = end_cnt - start_cnt\n",
        "  except:\n",
        "    print(\"Error with audio\")  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "www.youtube.com/watch?v=AvWWVOgaMlk\n",
            "FPS is : 30.000015705169986\n",
            "mmod_rectangles[[(532, 80) (871, 420)]]\n",
            "About to crop\n",
            "2738\n",
            "[MoviePy] Writing audio in Audio/AvWWVOgaMlk.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 547.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "before dict\n",
            "www.youtube.com/watch?v=Y8HMIm8mdns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FPS is : 29.97002997002997\n",
            "mmod_rectangles[[(574, 114) (710, 251)]]\n",
            "About to crop\n",
            "5173\n",
            "[MoviePy] Writing audio in Audio/Y8HMIm8mdns.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [00:00<00:00, 559.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "before dict\n",
            "www.youtube.com/watch?v=akwvpAiLFk0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FPS is : 25.0\n",
            "mmod_rectangles[[(822, 150) (986, 314)]]\n",
            "About to crop\n",
            "3668\n",
            "[MoviePy] Writing audio in Audio/akwvpAiLFk0.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:00<00:00, 568.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "before dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8euGG8fcN2C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing y_train for encoder and x_train for decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imq1NC9eNrw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(filenames):\n",
        "\n",
        "  faces = []\n",
        "  for f in filenames:\n",
        "    img = cv2.imread(f)\n",
        "    face_arr = asarray(img)\n",
        "    faces.append(face_arr)\n",
        "\n",
        "  samples = asarray(faces,'float32')\n",
        "\n",
        "  samples = preprocess_input(samples,version=2)\n",
        "\n",
        "  model = VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3),pooling='avg')\n",
        "\n",
        "  yhat = model.predict(samples)\n",
        "\n",
        "  return yhat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuX-U10yNpP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "3a87dbb5-a850-442c-b528-628884d6f8cf"
      },
      "source": [
        "face_list = []\n",
        "for elem in os.listdir('./Images'):\n",
        "  face_list.append('./Images/' + elem)\n",
        "y_train_encoder = get_embeddings(face_list)\n",
        "x_train_decoder = get_embeddings(face_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gu1QuBlDTjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4bc4b36-bbe4-4e4c-b229-7afa2d786925"
      },
      "source": [
        "y_train_encoder.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUO7eAcrEMu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using y_train to create decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHQeTV4EEP-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input is y_train and output is images from Images folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLa9Bl1REQEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmenting Audio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQNrIifEQGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "402342e3-9535-4b6d-dc2e-f77924ee43ad"
      },
      "source": [
        "# shutil.rmtree('Processed_Audio')\n",
        "os.mkdir('Processed_Audio')\n",
        "temp_dict = dict_audio.copy()\n",
        "for elem in os.listdir('./Audio'):\n",
        "  sound = AudioSegment.from_mp3('./Audio/' + elem)\n",
        "  sound_new = sound\n",
        "  while temp_dict[elem[:-4]] < 6:\n",
        "    print(\"here\")\n",
        "    sound_new += sound\n",
        "    temp = temp_dict[elem[:-4]]\n",
        "    temp_dict[elem[:-4]] = 2*temp\n",
        "    sound = sound_new\n",
        "\n",
        "  extract = sound[0:6*1000]\n",
        "\n",
        "  extract.export('Processed_Audio/' + elem, format=\"mp3\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "here\n",
            "here\n",
            "here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrFy2ucN3_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing x_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cpDGkHfd0XK3",
        "outputId": "3e2525af-5b47-40c3-c7bb-51cdb8010b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# shutil.rmtree('Spectograms')\n",
        "os.mkdir('Spectograms')\n",
        "for filename in os.listdir(\"./Processed_Audio\"):\n",
        "  audio_path = './Processed_Audio/' + filename\n",
        "  x , sr = librosa.load(audio_path,sr = 15925)\n",
        "  print(audio_path)\n",
        "  print(type(x), type(sr))\n",
        "  print(x.shape, sr)\n",
        "  ipd.Audio(audio_path)\n",
        "  window_size = 25\n",
        "  window = np.hanning(window_size)\n",
        "  h1 = 160\n",
        "  print(h1)\n",
        "\n",
        "  stft  = librosa.core.spectrum.stft(x, n_fft=512, hop_length=h1,win_length=window_size, window=window)\n",
        "  out = 2 * np.abs(stft) / np.sum(window_size)\n",
        "  with open('./Spectograms/' + filename[:-4] + '.pkl','wb') as f:\n",
        "    pickle.dump(stft,f)\n",
        "  \n",
        "  # librosa.display.waveplot(x, sr=sr)\n",
        "  # mfccs = librosa.feature.mfcc(x, sr=sr)\n",
        "  # print(mfccs.shape)\n",
        "  # librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "  # print()\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./Processed_Audio/Y8HMIm8mdns.mp3\n",
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(95550,) 15925\n",
            "160\n",
            "./Processed_Audio/akwvpAiLFk0.mp3\n",
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(95550,) 15925\n",
            "160\n",
            "./Processed_Audio/AvWWVOgaMlk.mp3\n",
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(95550,) 15925\n",
            "160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW6Tl0d9q1pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Todo: For all pickle files in spectogram "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T77t_QknmatO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encoder_network_input(k):\n",
        "  mod = np.zeros((257,598))\n",
        "  for i in range(257):\n",
        "    for j in range(598):\n",
        "      mod[i][j] = np.abs(k[i][j])\n",
        "\n",
        "  theta_ = np.zeros((257,598))\n",
        "  for i in range(257):\n",
        "    for j in range(598):\n",
        "      theta_[i][j] = np.angle(k[i][j])\n",
        "\n",
        "  real = np.zeros((257,598))\n",
        "  complex_ = np.zeros((257,598))\n",
        "  for i in range(257):\n",
        "    for j in range(598):\n",
        "      temp = mod[i][j]\n",
        "      real[i][j] = temp * math.cos(complex_[i][j])\n",
        "      complex_[i][j] = temp * math.sin(complex_[i][j])\n",
        "\n",
        "  real = np.expand_dims(real,axis = 0)\n",
        "  complex_ = np.expand_dims(complex_,axis = 0)\n",
        "  combined = np.concatenate((real,complex_))\n",
        "\n",
        "  return combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APg38HYXms72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "af650059-3faf-49e9-85e2-25c6e0462c99"
      },
      "source": [
        "encoder_input = []\n",
        "for elem in os.listdir('./Spectograms/'):\n",
        "  with open('./Spectograms/' + elem,'rb') as f:\n",
        "    print('./Spectograms/' + elem)\n",
        "    k = pickle.load(f)\n",
        "    print(k.shape)\n",
        "\n",
        "  encoder_input.append(get_encoder_network_input(k))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./Spectograms/AvWWVOgaMlk.pkl\n",
            "(257, 598)\n",
            "./Spectograms/Y8HMIm8mdns.pkl\n",
            "(257, 598)\n",
            "./Spectograms/akwvpAiLFk0.pkl\n",
            "(257, 598)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEFnKuTcnPLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cf410c2-21d0-4485-8fe0-5c32ef02b3fe"
      },
      "source": [
        "len(encoder_input)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygv6iaaD2fOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For encoder\n",
        "\n",
        "# Input : encoder input as np array\n",
        "# Output : y_train_encoder\n",
        "\n",
        "# FOr decoder\n",
        "\n",
        "# Input : x_train_encoder\n",
        "# Output : Images from Images folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoZMC2Er8lC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense,BatchNormalization,LeakyReLU,MaxPool2D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4lzI_hM3Z8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: create decoder output into np array from images folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_onUcUj3hxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENCODER MODEL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYcDKaPZ3k7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_enc_train = np.asarray(encoder_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GImxxEAK3k-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a775247-58b8-4b66-8229-4f3bcd7cd828"
      },
      "source": [
        "x_enc_train.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2, 257, 598)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0uc9IIn3lET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38d2fe1b-a8e9-476a-f184-fa14f067d975"
      },
      "source": [
        "# input = tf.keras.layers.Input(shape=x_enc_train.shape)\n",
        "# x = tf.keras.layers.Conv2D(64, kernel_size = (4,4), strides=(1,1), padding = 'same')(input)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=[2,257,598],use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,1)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,1)))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,1)))\n",
        "\n",
        "model.add(Conv2D(512, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=x_enc_train.shape,use_bias=False))\n",
        "\n",
        "model.add(AvgPool2D(strides = (1,1)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2048,activation='relu'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_6/MaxPool' (op: 'MaxPool') with input shapes: [?,1,257,128].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-c19f7296e187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_enc_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    266\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    267\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   4267\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   4268\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4269\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   4270\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4271\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   3813\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3815\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5672\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5673\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5674\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5675\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5676\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_6/MaxPool' (op: 'MaxPool') with input shapes: [?,1,257,128]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xloiho5b3lDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DECODER MODEL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmapmBK88z_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "bd81301e-0af6-4fd1-f97b-84ae703d4326"
      },
      "source": [
        "filenames = []\n",
        "for elem in os.listdir('./Images'):\n",
        "  filenames.append(elem)\n",
        "\n",
        "decoder_train_df = pd.DataFrame(filenames,columns = ['filename'])\n",
        "decoder_train_df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Y8HMIm8mdns.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>akwvpAiLFk0.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AvWWVOgaMlk.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename\n",
              "0  Y8HMIm8mdns.png\n",
              "1  akwvpAiLFk0.png\n",
              "2  AvWWVOgaMlk.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOIHHsND3nFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OwkZwKykJOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Processed_Audio/AvWWVOgaMlk.mp3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtmgZ3qAXPQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}