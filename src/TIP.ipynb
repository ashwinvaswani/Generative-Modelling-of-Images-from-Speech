{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinvaswani/Generative-Modelling-of-Images-from-Speech/blob/master/src/TIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nalKfifObQ",
        "colab_type": "code",
        "outputId": "55b33eca-7550-4ded-cf0c-3efbaf46c545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install pydub\n",
        "!pip install pytube\n",
        "!pip install mtcnn\n",
        "!pip install keras-vggface"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n",
            "Collecting pytube\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/00/62118c1e9e597aed08ddf7d9a6ca45ec95147367280aba73e8b82816fec1/pytube-9.5.3-py3-none-any.whl\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-9.5.3\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/c7/8546b18fbd367b156c5bbbbaa8912ab31c8129171523ff8b47b546d70b09/mtcnn-0.0.9.tar.gz (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mtcnn\n",
            "  Building wheel for mtcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtcnn: filename=mtcnn-0.0.9-cp36-none-any.whl size=2257690 sha256=5720c1fe7ffc3f3a186b83bb46da892d8e0b2ace239887a0723081aad5417260\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/81/65/6363fa5aafd7a155c896591e0c7c6e27b69642aa82b9cbf076\n",
            "Successfully built mtcnn\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.0.9\n",
            "Collecting keras-vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.17.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (4.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface) (0.46)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag9GmoUm-5Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2 \n",
        "import os\n",
        "import sys\n",
        "import moviepy.editor as mp\n",
        "import pickle\n",
        "\n",
        "import math\n",
        "from math import ceil\n",
        "from math import floor\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pytube import YouTube\n",
        "\n",
        "import shutil\n",
        "\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import dlib\n",
        "\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbnCURGp_E8W",
        "colab_type": "code",
        "outputId": "e4dfda0a-8561-448f-96e2-987b332a948e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZAtSuy6_I3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './drive/My Drive/TIP/Dataset/'\n",
        "PATH_TO_MAIN = './drive/My Drive/TIP/'\n",
        "YT_LINK = 'www.youtube.com/watch?v='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gql85lJ_UX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['YouTube_ID', 'start_segment', 'end_segment', 'X_coordinate', 'Y_coordinate']\n",
        "train_df = pd.read_csv(PATH + 'avspeech_train.csv',names = column_names)\n",
        "test_df = pd.read_csv(PATH + 'avspeech_test.csv',names = column_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNkryG8n_u4g",
        "colab_type": "code",
        "outputId": "af5ffcd2-bee0-4be9-b85e-fca8b4668326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YouTube_ID</th>\n",
              "      <th>start_segment</th>\n",
              "      <th>end_segment</th>\n",
              "      <th>X_coordinate</th>\n",
              "      <th>Y_coordinate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CJoOwXcjhds</td>\n",
              "      <td>233.266000</td>\n",
              "      <td>239.367000</td>\n",
              "      <td>0.780469</td>\n",
              "      <td>0.670833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AvWWVOgaMlk</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>93.566667</td>\n",
              "      <td>0.586719</td>\n",
              "      <td>0.311111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Y8HMIm8mdns</td>\n",
              "      <td>171.607767</td>\n",
              "      <td>174.607767</td>\n",
              "      <td>0.505729</td>\n",
              "      <td>0.240741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>akwvpAiLFk0</td>\n",
              "      <td>144.680000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>0.698438</td>\n",
              "      <td>0.288889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Swss72CHSWg</td>\n",
              "      <td>90.023267</td>\n",
              "      <td>97.297200</td>\n",
              "      <td>0.230729</td>\n",
              "      <td>0.204630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YouTube_ID  start_segment  end_segment  X_coordinate  Y_coordinate\n",
              "0  CJoOwXcjhds     233.266000   239.367000      0.780469      0.670833\n",
              "1  AvWWVOgaMlk      90.000000    93.566667      0.586719      0.311111\n",
              "2  Y8HMIm8mdns     171.607767   174.607767      0.505729      0.240741\n",
              "3  akwvpAiLFk0     144.680000   150.000000      0.698438      0.288889\n",
              "4  Swss72CHSWg      90.023267    97.297200      0.230729      0.204630"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwN707L_x-H",
        "colab_type": "code",
        "outputId": "2603bf0c-a4bf-46d5-b1b2-69708d2fcc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YouTube_ID</th>\n",
              "      <th>start_segment</th>\n",
              "      <th>end_segment</th>\n",
              "      <th>X_coordinate</th>\n",
              "      <th>Y_coordinate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u5MPyrRJPmc</td>\n",
              "      <td>108.2400</td>\n",
              "      <td>111.240000</td>\n",
              "      <td>0.849219</td>\n",
              "      <td>0.305556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H1ulMfj5wRY</td>\n",
              "      <td>112.3200</td>\n",
              "      <td>116.940000</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.345833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-wuxbgMRIWs</td>\n",
              "      <td>30.0300</td>\n",
              "      <td>36.745044</td>\n",
              "      <td>0.744531</td>\n",
              "      <td>0.211111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GNRPRH-E-sI</td>\n",
              "      <td>30.2302</td>\n",
              "      <td>38.171467</td>\n",
              "      <td>0.333594</td>\n",
              "      <td>0.494444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VvcwAGkSy2o</td>\n",
              "      <td>240.2000</td>\n",
              "      <td>253.366667</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>0.372222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YouTube_ID  start_segment  end_segment  X_coordinate  Y_coordinate\n",
              "0  u5MPyrRJPmc       108.2400   111.240000      0.849219      0.305556\n",
              "1  H1ulMfj5wRY       112.3200   116.940000      0.112500      0.345833\n",
              "2  -wuxbgMRIWs        30.0300    36.745044      0.744531      0.211111\n",
              "3  GNRPRH-E-sI        30.2302    38.171467      0.333594      0.494444\n",
              "4  VvcwAGkSy2o       240.2000   253.366667      0.491667      0.372222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPS_NJEsVX2v",
        "colab_type": "code",
        "outputId": "ccd82a29-3c75-4717-bf7e-a384c883d10c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "YT_LINK + train_df.iloc[2][\"YouTube_ID\"]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'www.youtube.com/watch?v=Y8HMIm8mdns'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOenYxt1VJQM",
        "colab_type": "code",
        "outputId": "e1e886d2-d8c6-42ae-8e89-c9b00b9f63bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "\n",
        "# shutil.rmtree('Images')\n",
        "# shutil.rmtree('Audio')\n",
        "# shutil.rmtree('Videos')\n",
        "os.mkdir(\"Images\")\n",
        "os.mkdir(\"Audio\")\n",
        "os.mkdir(\"Videos\")\n",
        "\n",
        "len_train = train_df.shape[0]\n",
        "count_unsuccessful = 0\n",
        "dict_audio = {}\n",
        "\n",
        "for i in range(1,4):\n",
        "\n",
        "  print(YT_LINK + train_df.iloc[i][\"YouTube_ID\"])\n",
        "  try:\n",
        "    yt = YouTube(YT_LINK + train_df.iloc[i][\"YouTube_ID\"])\n",
        "    stream = yt.streams.first()\n",
        "    stream.download(output_path = 'Videos/',filename = train_df.iloc[i][\"YouTube_ID\"])\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(\"Videos/\" + train_df.iloc[i][\"YouTube_ID\"] + '.mp4') \n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    \n",
        "    count = 0\n",
        "\n",
        "    dir_name = train_df.iloc[i][\"YouTube_ID\"]\n",
        "    \n",
        "    print(\"FPS is : \"  + str(fps))\n",
        "    start_cnt = train_df.iloc[i][\"start_segment\"]\n",
        "    end_cnt = train_df.iloc[i][\"end_segment\"]\n",
        "    \n",
        "    while(1):\n",
        "\n",
        "        ret,frame = cap.read()\n",
        "\n",
        "        if ret == 1:\n",
        "\n",
        "          count += 1\n",
        "\n",
        "          (h, w) = frame.shape[:2]\n",
        "\n",
        "          if (((start_cnt + end_cnt)*fps)/2) - 16 < count < (((start_cnt + end_cnt)*fps)/2) + 16:\n",
        "            dnnFaceDetector = dlib.cnn_face_detection_model_v1( PATH_TO_MAIN + \"Face_detection/mmod_human_face_detector.dat\")\n",
        "            faceRects = dnnFaceDetector(frame, 0)\n",
        "            print(faceRects)\n",
        "            for faceRect in faceRects:\n",
        "                x1 = faceRect.rect.left()\n",
        "                y1 = faceRect.rect.top()\n",
        "                x2 = faceRect.rect.right()\n",
        "                y2 = faceRect.rect.bottom()\n",
        "                img = frame[y1:y2, x1:x2]\n",
        "                print(\"About to crop\")\n",
        "                print(count)\n",
        "                img = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                cv2.imwrite('Images/' +dir_name + '.png', img)\n",
        "            break\n",
        "\n",
        "\n",
        "          if count > int(end_cnt*fps):\n",
        "            break\n",
        "          k = cv2.waitKey(1)\n",
        "          if k == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "  except:\n",
        "    print(\"SORRY!!! The video is unavailable\")\n",
        "    count_unsuccessful += 1\n",
        "    \n",
        "  try:\n",
        "    clip = mp.VideoFileClip(\"Videos/\" + train_df.iloc[i][\"YouTube_ID\"] + '.mp4').subclip(start_cnt,end_cnt)\n",
        "    clip.audio.write_audiofile(\"Audio/\" + train_df.iloc[i][\"YouTube_ID\"] +'.mp3') \n",
        "    print(\"before dict\")\n",
        "    dict_audio[train_df.iloc[i][\"YouTube_ID\"]] = end_cnt - start_cnt\n",
        "  except:\n",
        "    print(\"Error with audio\")  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "www.youtube.com/watch?v=AvWWVOgaMlk\n",
            "FPS is : 30.000015705169986\n",
            "mmod_rectangles[[(532, 80) (871, 420)]]\n",
            "About to crop\n",
            "2738\n",
            "[MoviePy] Writing audio in Audio/AvWWVOgaMlk.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 543.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "before dict\n",
            "www.youtube.com/watch?v=Y8HMIm8mdns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FPS is : 29.97002997002997\n",
            "mmod_rectangles[[(574, 114) (710, 251)]]\n",
            "About to crop\n",
            "5173\n",
            "[MoviePy] Writing audio in Audio/Y8HMIm8mdns.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [00:00<00:00, 574.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "before dict\n",
            "www.youtube.com/watch?v=akwvpAiLFk0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FPS is : 25.0\n",
            "mmod_rectangles[[(822, 150) (986, 314)]]\n",
            "About to crop\n",
            "3668\n",
            "[MoviePy] Writing audio in Audio/akwvpAiLFk0.mp3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:00<00:00, 536.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "before dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8euGG8fcN2C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing y_train for encoder and x_train for decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imq1NC9eNrw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(filenames):\n",
        "\n",
        "  faces = []\n",
        "  for f in filenames:\n",
        "    img = cv2.imread(f)\n",
        "    face_arr = asarray(img)\n",
        "    faces.append(face_arr)\n",
        "\n",
        "  samples = asarray(faces,'float32')\n",
        "\n",
        "  samples = preprocess_input(samples,version=2)\n",
        "\n",
        "  model = VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3),pooling='avg')\n",
        "\n",
        "  yhat = model.predict(samples)\n",
        "\n",
        "  return yhat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuX-U10yNpP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "925a2a33-ea91-4d3c-d30c-9acd44438aef"
      },
      "source": [
        "face_list = []\n",
        "for elem in os.listdir('./Images'):\n",
        "  face_list.append('./Images/' + elem)\n",
        "y_train_encoder = get_embeddings(face_list)\n",
        "x_train_decoder = get_embeddings(face_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gu1QuBlDTjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f869fa2d-2ca0-441f-8aeb-4520068e4551"
      },
      "source": [
        "y_train_encoder.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUO7eAcrEMu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using y_train to create decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHQeTV4EEP-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input is y_train and output is images from Images folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLa9Bl1REQEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmenting Audio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQNrIifEQGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fa69c574-6c75-4d8b-f3ef-57791553faff"
      },
      "source": [
        "# shutil.rmtree('Processed_Audio')\n",
        "os.mkdir('Processed_Audio')\n",
        "temp_dict = dict_audio.copy()\n",
        "for elem in os.listdir('./Audio'):\n",
        "  sound = AudioSegment.from_mp3('./Audio/' + elem)\n",
        "  sound_new = sound\n",
        "  while temp_dict[elem[:-4]] < 6:\n",
        "    print(\"here\")\n",
        "    sound_new += sound\n",
        "    temp = temp_dict[elem[:-4]]\n",
        "    temp_dict[elem[:-4]] = 2*temp\n",
        "    sound = sound_new\n",
        "\n",
        "  extract = sound[0:6*1000]\n",
        "\n",
        "  extract.export('Processed_Audio/' + elem, format=\"mp3\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "here\n",
            "here\n",
            "here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrFy2ucN3_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing x_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cpDGkHfd0XK3",
        "outputId": "73cc93eb-5239-4c6a-e2a2-6cc39173da09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# shutil.rmtree('Spectograms')\n",
        "os.mkdir('Spectograms')\n",
        "for filename in os.listdir(\"./Processed_Audio\"):\n",
        "  audio_path = './Processed_Audio/' + filename\n",
        "  x , sr = librosa.load(audio_path,sr = 15925)\n",
        "  print(audio_path)\n",
        "  print(type(x), type(sr))\n",
        "  print(x.shape, sr)\n",
        "  ipd.Audio(audio_path)\n",
        "  window_size = 25\n",
        "  window = np.hanning(window_size)\n",
        "  h1 = 160\n",
        "  print(h1)\n",
        "\n",
        "  stft  = librosa.core.spectrum.stft(x, n_fft=512, hop_length=h1,win_length=window_size, window=window)\n",
        "  out = 2 * np.abs(stft) / np.sum(window_size)\n",
        "  with open('./Spectograms/' + filename[:-4] + '.pkl','wb') as f:\n",
        "    pickle.dump(stft,f)\n",
        "  \n",
        "  # librosa.display.waveplot(x, sr=sr)\n",
        "  # mfccs = librosa.feature.mfcc(x, sr=sr)\n",
        "  # print(mfccs.shape)\n",
        "  # librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "  # print()\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./Processed_Audio/Y8HMIm8mdns.mp3\n",
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(95550,) 15925\n",
            "160\n",
            "./Processed_Audio/akwvpAiLFk0.mp3\n",
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(95550,) 15925\n",
            "160\n",
            "./Processed_Audio/AvWWVOgaMlk.mp3\n",
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(95550,) 15925\n",
            "160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW6Tl0d9q1pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Todo: For all pickle files in spectogram "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T77t_QknmatO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encoder_network_input(k):\n",
        "  mod = np.zeros((257,598))\n",
        "  for i in range(257):\n",
        "    for j in range(598):\n",
        "      mod[i][j] = np.abs(k[i][j])\n",
        "\n",
        "  theta_ = np.zeros((257,598))\n",
        "  for i in range(257):\n",
        "    for j in range(598):\n",
        "      theta_[i][j] = np.angle(k[i][j])\n",
        "\n",
        "  real = np.zeros((257,598))\n",
        "  complex_ = np.zeros((257,598))\n",
        "  for i in range(257):\n",
        "    for j in range(598):\n",
        "      temp = mod[i][j]\n",
        "      real[i][j] = temp * math.cos(complex_[i][j])\n",
        "      complex_[i][j] = temp * math.sin(complex_[i][j])\n",
        "\n",
        "  real = np.expand_dims(real,axis = 0)\n",
        "  complex_ = np.expand_dims(complex_,axis = 0)\n",
        "  combined = np.concatenate((real,complex_))\n",
        "\n",
        "  return combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APg38HYXms72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2012a9d7-1b12-4521-97e5-ab82bacf3d65"
      },
      "source": [
        "encoder_input = []\n",
        "for elem in os.listdir('./Spectograms/'):\n",
        "  with open('./Spectograms/' + elem,'rb') as f:\n",
        "    print('./Spectograms/' + elem)\n",
        "    k = pickle.load(f)\n",
        "    print(k.shape)\n",
        "\n",
        "  encoder_input.append(np.transpose(get_encoder_network_input(k)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./Spectograms/AvWWVOgaMlk.pkl\n",
            "(257, 598)\n",
            "./Spectograms/Y8HMIm8mdns.pkl\n",
            "(257, 598)\n",
            "./Spectograms/akwvpAiLFk0.pkl\n",
            "(257, 598)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEFnKuTcnPLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3637f867-d40a-40b0-cd1a-d59a4ef2cf98"
      },
      "source": [
        "len(encoder_input)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygv6iaaD2fOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For encoder\n",
        "\n",
        "# Input : encoder input as np array\n",
        "# Output : y_train_encoder\n",
        "\n",
        "# FOr decoder\n",
        "\n",
        "# Input : x_train_encoder\n",
        "# Output : Images from Images folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoZMC2Er8lC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D,AvgPool2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense,BatchNormalization,LeakyReLU,MaxPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2DTranspose,Reshape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4lzI_hM3Z8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: create decoder output into np array from images folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_onUcUj3hxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENCODER MODEL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYcDKaPZ3k7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_enc_train = np.asarray(encoder_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GImxxEAK3k-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5951b40-3c23-4640-cc67-3ea7c52efd1e"
      },
      "source": [
        "x_enc_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 598, 257, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtBu-IWVfEK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9f21df3-018e-42b6-bfd5-0c585c46720e"
      },
      "source": [
        "y_train_encoder.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwBeWwxod6B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(x_enc_train,y_train_encoder,test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o_HE2bOdlX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "  \n",
        "def custom_loss(y_pred, y_true):\n",
        "  y_pred= tf.cast(y_pred, tf.float64) \n",
        "  y_true= tf.cast(y_true, tf.float64)\n",
        "  y_pred=tf.nn.relu(y_pred) \n",
        "  return tf.sqrt(tf.reduce_mean(tf.squared_difference(tf.log1p(y_pred), tf.log1p(y_true))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0uc9IIn3lET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7287a44-baad-46f0-f41e-6ece83eec0e3"
      },
      "source": [
        "# input = tf.keras.layers.Input(shape=x_enc_train.shape)\n",
        "# x = tf.keras.layers.Conv2D(64, kernel_size = (4,4), strides=(1,1), padding = 'same')(input)\n",
        "\n",
        "model_encoder = Sequential()\n",
        "model_encoder.add(Conv2D(64, kernel_size=(4,4),strides=(1,1), padding='same',  input_shape=[598,257,2],use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(Conv2D(64, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(Conv2D(128, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(MaxPool2D(pool_size=(2,1)))\n",
        "\n",
        "model_encoder.add(Conv2D(128, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(MaxPool2D(pool_size=(2,1)))\n",
        "\n",
        "model_encoder.add(Conv2D(256, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(MaxPool2D(pool_size=(2,1)))\n",
        "\n",
        "model_encoder.add(Conv2D(512, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        " \n",
        "model_encoder.add(Conv2D(512, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(Conv2D(512, kernel_size=(4,4),strides=(1,1), padding='same', use_bias=False))\n",
        "\n",
        "model_encoder.add(AvgPool2D(strides = (1,1)))\n",
        "model_encoder.add(LeakyReLU(alpha=0.1))\n",
        "model_encoder.add(BatchNormalization())\n",
        "\n",
        "model_encoder.add(Flatten())\n",
        "model_encoder.add(Dense(4096,activation='relu'))\n",
        "model_encoder.add(Dropout(0.2))\n",
        "\n",
        "model_encoder.add(Dense(2048,activation='relu'))\n",
        "\n",
        "model_encoder.summary()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 598, 257, 64)      2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 598, 257, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 598, 257, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 598, 257, 64)      65536     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 598, 257, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 598, 257, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 598, 257, 128)     131072    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 598, 257, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 598, 257, 128)     512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 299, 257, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 299, 257, 128)     262144    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 299, 257, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 299, 257, 128)     512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 149, 257, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 149, 257, 256)     524288    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 149, 257, 256)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 149, 257, 256)     1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 257, 256)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 74, 257, 512)      2097152   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 74, 257, 512)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 74, 257, 512)      2048      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 74, 257, 512)      4194304   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 74, 257, 512)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 74, 257, 512)      2048      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 74, 257, 512)      4194304   \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 73, 256, 512)      0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 73, 256, 512)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 73, 256, 512)      2048      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9568256)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              3919158067\n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2048)              8390656   \n",
            "=================================================================\n",
            "Total params: 39,211,450,880\n",
            "Trainable params: 39,211,446,528\n",
            "Non-trainable params: 4,352\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJrHb9AwBy-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "443323e5-0b99-4079-ef0b-d3561a587b8c"
      },
      "source": [
        "model_encoder.compile(loss='mse',optimizer=Adam(lr=1e-3),metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFoBqibUBYJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "84ca73f7-74ef-4a18-b7c6-d9f35febc5cb"
      },
      "source": [
        "checkpoint_path = \"./cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        " \n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=7, monitor='val_loss'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    cp_callback\n",
        "]\n",
        " \n",
        " \n",
        "model_encoder.fit(X_train, y_train, batch_size=1,validation_data=(X_val, y_val), epochs=10 ,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2 samples, validate on 1 samples\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ep-QyPCRwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_2Gd0DwCR0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uygp3hldcuxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8AX8ezgcuzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccPZHgDtcuvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xloiho5b3lDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DECODER MODEL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmapmBK88z_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "02de4f09-cf40-4dd3-90dd-5238913b3e92"
      },
      "source": [
        "filenames = []\n",
        "for elem in os.listdir('./Images'):\n",
        "  filenames.append(elem)\n",
        "\n",
        "decoder_train_df = pd.DataFrame(filenames,columns = ['filename'])\n",
        "decoder_train_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Y8HMIm8mdns.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AvWWVOgaMlk.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>akwvpAiLFk0.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename\n",
              "0  Y8HMIm8mdns.png\n",
              "1  AvWWVOgaMlk.png\n",
              "2  akwvpAiLFk0.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOIHHsND3nFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1e6e0c7b-8008-4102-a4e1-f667e801b136"
      },
      "source": [
        "model_decoder = Sequential()\n",
        "model_decoder.add(Dense(14*14*256,input_shape = [2048],activation='relu'))\n",
        "if K.image_data_format() == 'channels_first':\n",
        "      model_decoder.add(Reshape((256, 14, 14), input_shape=(256 * 14 * 14,)))\n",
        "      bn_axis = 1\n",
        "else:\n",
        "      model_decoder.add(Reshape((14, 14, 256), input_shape=(256 * 14 * 14,)))\n",
        "      bn_axis = -1\n",
        "model_decoder.add(Conv2DTranspose(128,strides=2,kernel_size=2))\n",
        "model_decoder.add(Conv2DTranspose(64,strides=2,kernel_size=2))\n",
        "model_decoder.add(Conv2DTranspose(32,strides=2,kernel_size=2))\n",
        "model_decoder.add(Conv2DTranspose(32,strides=2,kernel_size=2))\n",
        "\n",
        "model_decoder.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 50176)             102810624 \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       131200    \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 56, 56, 64)        32832     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 112, 112, 32)      8224      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 224, 224, 32)      4128      \n",
            "=================================================================\n",
            "Total params: 102,987,008\n",
            "Trainable params: 102,987,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e-AEC2LcUX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_decoder.compile(loss='mse',optimizer=Adam(lr=1e-3),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDXyyoiScVOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        " \n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=7, monitor='val_loss'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    cp_callback\n",
        "]\n",
        " \n",
        " \n",
        "# model_decoder.fit(trainX, trainY, batch_size=1,validation_data=(valX, valY), epochs=200 ,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIInCEOEcW9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mYD0pNFcW_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9EX7OwWcv8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMnL8P12cv6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZz4B_VYcv4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OwkZwKykJOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/Processed_Audio/AvWWVOgaMlk.mp3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtmgZ3qAXPQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}